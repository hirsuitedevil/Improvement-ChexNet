{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e610727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from utils import *\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statistics\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba106ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_labels = ['Atelectasis', 'Consolidation', 'Infiltration', 'Pneumothorax', 'Edema', 'Emphysema', 'Fibrosis', 'Effusion', 'Pneumonia', 'Pleural_Thickening',\n",
    "'Cardiomegaly', 'Nodule', 'Mass', 'Hernia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72361e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train_val = pd.read_csv('C:/Users/tanma/Downloads/archive/train_val_list.txt')\n",
    "labels_train_val.columns = ['Image_Index']\n",
    "\n",
    "labels_test = pd.read_csv('C:/Users/tanma/Downloads/archive/test_list.txt')\n",
    "labels_test.columns = ['Image_Index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b715d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv('C:/Users/tanma/Downloads/archive/Data_Entry_2017.csv')\n",
    "\n",
    "labels_df.columns = ['Image_Index', 'Finding_Labels', 'Follow_Up_#', 'Patient_ID',\n",
    "                  'Patient_Age', 'Patient_Gender', 'View_Position',\n",
    "                  'Original_Image_Width', 'Original_Image_Height',\n",
    "                  'Original_Image_Pixel_Spacing_X',\n",
    "                  'Original_Image_Pixel_Spacing_Y', 'dfd']\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bb7c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_disease = ['Effusion']\n",
    "binary_disease_str = 'Effusion'\n",
    "labels_df[binary_disease_str] = labels_df['Finding_Labels'].map(lambda x: binary_disease_str in x)\n",
    "\n",
    "# Print Class Mapping\n",
    "print(labels_df[binary_disease_str].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bb3f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_merge = pd.merge(left=labels_train_val, right=labels_df, left_on='Image_Index', right_on='Image_Index')\n",
    "\n",
    "test_merge = pd.merge(left=labels_test, right=labels_df, left_on='Image_Index', right_on='Image_Index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374843fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_merge['Finding_Labels'] = train_val_merge['Finding_Labels'].apply(lambda s: [l for l in str(s).split('|')])\n",
    "\n",
    "test_merge['Finding_Labels'] = test_merge['Finding_Labels'].apply(lambda s: [l for l in str(s).split('|')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98be4a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_glob = []\n",
    "num_glob = glob('C:/Users/tanma/Downloads/archive/images_001/images/*.png')+ glob('C:/Users/tanma/Downloads/archive/images_002/images/*.png')+ glob('C:/Users/tanma/Downloads/archive/images_003/images/*.png')+ glob('C:/Users/tanma/Downloads/archive/images_004/images/*.png')+ glob('C:/Users/tanma/Downloads/archive/images_005/images/*.png')+ glob('C:/Users/tanma/Downloads/archive/images_006/images/*.png')+ glob('C:/Users/tanma/Downloads/archive/images_007/images/*.png')+ glob('C:/Users/tanma/Downloads/archive/images_008/images/*.png')+ glob('C:/Users/tanma/Downloads/archive/images_009/images/*.png')+ glob('C:/Users/tanma/Downloads/archive/images_010/images/*.png')+ glob('C:/Users/tanma/Downloads/archive/images_011/images/*.png')+ glob('C:/Users/tanma/Downloads/archive/images_012/images/*.png')\n",
    "img_path = {os.path.basename(x): x for x in num_glob}\n",
    "train_val_merge['Paths'] = train_val_merge['Image_Index'].map(img_path.get)\n",
    "# Testing Mapping\n",
    "test_merge['Paths'] = test_merge['Image_Index'].map(img_path.get)\n",
    "train_val_merge.tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d70a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = np.unique(train_val_merge['Patient_ID'])\n",
    "test_patients = np.unique(test_merge['Patient_ID'])\n",
    "patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea74ae1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(patients,\n",
    "                                   test_size = 0.0669,\n",
    "                                   random_state = 2019,\n",
    "                                    shuffle= True\n",
    "                                   )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a97268",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_val_merge[train_val_merge['Patient_ID'].isin(train_df)]\n",
    "val_df = train_val_merge[train_val_merge['Patient_ID'].isin(val_df)]\n",
    "test_df = test_merge[test_merge['Patient_ID'].isin(test_patients)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4611a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0896a233",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = ImageDataGenerator(rescale=1./255,\n",
    "                                    samplewise_center=True, \n",
    "                                    samplewise_std_normalization=True, \n",
    "                                    horizontal_flip = True,\n",
    "                                    zoom_range=0.1, \n",
    "                                    height_shift_range=0.05, \n",
    "                                    width_shift_range=0.05,\n",
    "                                    rotation_range=5\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4432318a",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (224,224)\n",
    "train_gen = train_data_gen.flow_from_dataframe(dataframe=train_df, \n",
    "                                                directory=None,\n",
    "                                                shuffle= True,\n",
    "                                                seed = 2,\n",
    "                                                x_col = 'Paths',\n",
    "                                                y_col = binary_disease, \n",
    "                                                target_size = IMG_SIZE,\n",
    "                                                class_mode='raw',\n",
    "                                                classes = disease_labels,\n",
    "                                                color_mode = 'rgb',\n",
    "                                                batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1cdddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_gen = train_data_gen.flow_from_dataframe(\n",
    "                                            dataframe=val_df, \n",
    "                                            directory=None,\n",
    "                                            shuffle= True,\n",
    "                                            seed = 2,\n",
    "                                            x_col = 'Paths',\n",
    "                                            y_col = binary_disease, \n",
    "                                            target_size = IMG_SIZE,\n",
    "                                            classes = disease_labels,\n",
    "                                            class_mode='raw',\n",
    "                                            color_mode = 'rgb',\n",
    "                                            batch_size = 16\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153316dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_IND = 224\n",
    "train_data = tf.data.Dataset.from_generator(lambda: train_gen,\n",
    "                                            output_types=(tf.float32, tf.int32),\n",
    "                                           output_shapes=([None, IMG_IND, IMG_IND, 3], [None, 1]))\n",
    "val_data = tf.data.Dataset.from_generator(lambda: val_gen,\n",
    "                                          output_types=(tf.float32, tf.int32),\n",
    "                                         output_shapes=([None, IMG_IND, IMG_IND, 3], [None, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d593ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = np.array(train_df['Paths'])\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
    "\n",
    "images_to_augment = []\n",
    "\n",
    "for image_path in image_paths[:4]:\n",
    "    image = load_img(image_path, target_size=(IMG_IND, IMG_IND))\n",
    "    image = img_to_array(image)\n",
    "    images_to_augment.append(image)\n",
    "    \n",
    "images_to_augment = np.array(images_to_augment)\n",
    "\n",
    "images_augmented = next(train_data_gen.flow(x=images_to_augment,\n",
    "                                batch_size=10,\n",
    "                                shuffle=False))\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "\n",
    "fig, axes = plt.subplots(2, 2)\n",
    "\n",
    "for i in range(2):\n",
    "    axes[i, 0].imshow(array_to_img(images_to_augment[i]), \n",
    "                      #horizontal_flip = True,\n",
    "                      interpolation='nearest')\n",
    "    \n",
    "    axes[i, 1].imshow(array_to_img(images_augmented[i]), \n",
    "                      interpolation='nearest')\n",
    "    \n",
    "    axes[i, 0].set_xticks([])\n",
    "    axes[i, 1].set_xticks([])\n",
    "    \n",
    "    axes[i, 0].set_yticks([])\n",
    "    axes[i, 1].set_yticks([])\n",
    "    \n",
    "    axes[i, 0].set_yticks([])\n",
    "    axes[i, 1].set_yticks([])\n",
    "    \n",
    "    axes[i, 0].set_xticks([])\n",
    "    axes[i, 1].set_xticks([])\n",
    "    \n",
    "    axes[i, 0].set_yticks([])\n",
    "    axes[i, 1].set_yticks([])\n",
    "    \n",
    "    axes[i, 0].set_yticks([])\n",
    "    axes[i, 1].set_yticks([])\n",
    "    \n",
    "columns = ['Base Image', 'Augmented Image']\n",
    "for ax, column in zip(axes[0], columns):\n",
    "    ax.set_title(column) \n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf3eec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.DenseNet121(input_shape=(224,224,3),include_top=False,weights='imagenet')\n",
    "base_model.trainable = True\n",
    "top_model = tf.keras.models.Sequential()\n",
    "top_model.add(tf.keras.layers.Flatten(input_shape=base_model.output_shape[1:]))\n",
    "top_model.add(tf.keras.layers.Dropout(0.5))\n",
    "top_model.add(tf.keras.layers.Dense(64, kernel_initializer='normal'))\n",
    "top_model.add(tf.keras.layers.BatchNormalization())\n",
    "top_model.add(tf.keras.layers.Activation('relu'))\n",
    "top_model.add(tf.keras.layers.Dense(64, kernel_initializer='normal'))\n",
    "top_model.add(tf.keras.layers.BatchNormalization())\n",
    "top_model.add(tf.keras.layers.Activation('relu'))\n",
    "top_model.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n",
    "model = tf.keras.models.Model(base_model.inputs, top_model(base_model.output))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5f2db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [tf.keras.metrics.BinaryAccuracy(name='BinaryAccuracy')]\n",
    "model.compile(loss = 'categorical_crossentropy',optimizer = 'Adam',metrics = METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1919e133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training/Validation Steps\n",
    "LEARNING_RATE_PATIENCE = 5\n",
    "# Dynamic Learning Rate\n",
    "reduced_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                                                monitor='val_loss',\n",
    "                                                factor=.05,\n",
    "                                                patience=LEARNING_RATE_PATIENCE,\n",
    "                                                verbose=1,\n",
    "                                                mode='min',\n",
    "                                                cooldown=0,\n",
    "                                                min_lr=1e-6 \n",
    "                                                )\n",
    "# auroc = MultipleClassAUROC(\n",
    "#                             sequence = x_val,\n",
    "#                             class_names=binary_disease,\n",
    "#                             weights_path=CALLBACKS_DIR,\n",
    "#                             stats={},\n",
    "#                             workers=1,\n",
    "#                             )\n",
    "\n",
    "class_weight = {\n",
    "    0: 1.,\n",
    "    1: 2.0\n",
    "}\n",
    "BATCH_SIZE = 16\n",
    "train_steps = train_gen.samples // 64\n",
    "val_steps = val_gen.samples // 64\n",
    "history = model.fit(\n",
    "                    train_data.prefetch(buffer_size=tf.data.experimental.AUTOTUNE) ,\n",
    "                    steps_per_epoch = 252, \n",
    "                    validation_data=  val_data.prefetch(buffer_size=tf.data.experimental.AUTOTUNE),    \n",
    "                    validation_steps = 17, \n",
    "                    epochs=10,\n",
    "                    use_multiprocessing=True,\n",
    "                    class_weight = class_weight,\n",
    "                    callbacks=[reduced_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3d55c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pred_Y = model.predict(x_test,\n",
    "                        steps=64,\n",
    "                        verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0830b7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "plt.matshow(confusion_matrix(y_test, pred_Y>0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4882bd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb97605e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our Changes \n",
    "base_model = tf.keras.applications.DenseNet121(input_shape=(224,224,3),include_top=False,weights='imagenet')\n",
    "model = tf.keras.Sequential([base_model,tf.keras.layers.Dense(units = 14, activation = 'linear'),tf.keras.layers.Dense(units = 14,activation = 'sigmoid')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25894e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultipleClassAUROC(Callback):\n",
    "    \"\"\"\n",
    "    Monitor mean AUROC and update model\n",
    "    \"\"\"\n",
    "    def __init__(self, sequence, class_names, weights_path, stats=None, workers=1):\n",
    "        super(Callback, self).__init__()\n",
    "        #self.steps=STEPS ############################\n",
    "        self.sequence = sequence\n",
    "        self.workers = workers\n",
    "        self.class_names = class_names\n",
    "        self.weights_path = weights_path\n",
    "        self.best_weights_path = os.path.join(\n",
    "            os.path.split(weights_path)[0],\n",
    "            f\"best_{os.path.split(weights_path)[1]}\",\n",
    "        )\n",
    "        self.best_auroc_log_path = os.path.join(\n",
    "            os.path.split(weights_path)[0],\n",
    "            \"best_auroc.log\",\n",
    "        )\n",
    "        self.stats_output_path = os.path.join(\n",
    "            os.path.split(weights_path)[0],\n",
    "            \".training_stats.json\"\n",
    "        )\n",
    "        # for resuming previous training\n",
    "        if stats:\n",
    "            self.stats = stats\n",
    "        else:\n",
    "             self.stats = {\"best_mean_auroc\": 0}\n",
    "        self.aurocs = {}\n",
    "        for c in self.class_names:\n",
    "            self.aurocs[c] = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \"\"\"\n",
    "        Calculate the average AUROC and save the best model weights according\n",
    "        to this metric.\n",
    "        \"\"\"\n",
    "        print(\"\\n*********************************\")\n",
    "        self.stats[\"lr\"] = float(kb.eval(self.model.optimizer.lr))\n",
    "        print(f\"current learning rate: {self.stats['lr']}\")\n",
    "        #LR_LOG.append(self.stats['lr'])\n",
    "\n",
    "        y_hat = model.predict(self.sequence,verbose=1)\n",
    "        \n",
    "        pred_indices = np.argmax(y_hat,axis=1)\n",
    "\n",
    "        y = y_val \n",
    "        \n",
    "        print(f\"*** epoch#{epoch + 1} dev auroc ***\")\n",
    "        current_auroc = []\n",
    "        try:\n",
    "            score = roc_auc_score(y, y_hat)\n",
    "        except ValueError:\n",
    "            score = 0\n",
    "\n",
    "        current_auroc.append(score)\n",
    "        EPOCH = epoch + 1 \n",
    "\n",
    "        print(\"*********************************\")\n",
    "\n",
    "        mean_auroc = np.mean(current_auroc)\n",
    "        MEAN_AUROC.append(mean_auroc)\n",
    "        print(f\"Effusion auroc: {mean_auroc}\\n\")\n",
    "        \n",
    "        print(\"*********************************\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
